{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL-with-pytorch - 10 [CNN-RNN].ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bIAYbYajk1w9","colab_type":"text"},"source":["<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","\n","      \n","| Name | Description | Date\n","| :- |-------------: | :-:\n","|Reza Hashemi| Multi Layer Perceptrons - CNN-RNN network 10th  | Finalized on 23rd of August 2019 | width=\"750\" align=\"center\"></a></p>\n","</div>\n","\n","# CNN-RNN network\n","- CNNs and RNNs both have their own strengths and drawbacks. Hence, it is sometimes recommended to combine the two to model highly complicated data\n","- Here, we combine the two to classify fashion image dataset (Fashion-MNIST)"]},{"cell_type":"code","metadata":{"id":"GVU5-yp3N89I","colab_type":"code","outputId":"b241b5a2-7470-44e7-f2d4-e0e6816f48fb","executionInfo":{"status":"ok","timestamp":1566589544370,"user_tz":240,"elapsed":3018,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!pip3 install torch torchvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8yy37hEYOEiQ","colab_type":"code","outputId":"eca678a4-19c3-40f1-a3ac-9d878c0b6a1c","executionInfo":{"status":"ok","timestamp":1566589548871,"user_tz":240,"elapsed":807,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import pandas as pd\n","import torch, torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","torch.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.1.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"ewrw93tt2BfV","colab_type":"text"},"source":["## 1. Import & process dataset\n","- Fashion MNIST dataset from torchvision \n","- [Original dataset source](https://github.com/zalandoresearch/fashion-mnist), [paper](https://arxiv.org/abs/1708.07747)\n","\n","![](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"]},{"cell_type":"code","metadata":{"id":"SxDHXFEsf5em","colab_type":"code","outputId":"247ced9a-3d00-4e86-9b0c-c77613fb4c82","executionInfo":{"status":"ok","timestamp":1566589555513,"user_tz":240,"elapsed":4621,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["from torchvision import datasets\n","import torchvision.transforms as transforms\n","\n","train_dataset = datasets.FashionMNIST(root = \"/\", train = True, download = True, transform = transforms.ToTensor())\n","test_dataset = datasets.FashionMNIST(root = \"/\", train = False, download = True, transform = transforms.ToTensor())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /FashionMNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["26427392it [00:02, 12266940.50it/s]                              \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting /FashionMNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 95447.30it/s]                            \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting /FashionMNIST/raw/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["4423680it [00:01, 4019779.87it/s]                             \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting /FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["8192it [00:00, 30913.95it/s]            "],"name":"stderr"},{"output_type":"stream","text":["Extracting /FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"L5b7U5zL4fQb","colab_type":"code","colab":{}},"source":["# create data loaders \n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 128, shuffle = True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 128, shuffle = False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9nznVMdo5edZ","colab_type":"text"},"source":["## 2. Creating CNN-RNN model and training\n","\n","- Create and train  CNN-RNN model for fashion MNIST image classification.\n","\n","\n","![](https://www.researchgate.net/profile/Maulik_Kamdar/publication/322167103/figure/fig5/AS:631611880124465@1527599415555/CRNN-Architecture-Overview-Combining-CNN-and-RNN-to-predict-the-methylation-state-from.png)"]},{"cell_type":"code","metadata":{"id":"AQawpMRPI7jm","colab_type":"code","colab":{}},"source":["# create CNN with one convolution/pooling layer\n","class net(nn.Module):\n","  def __init__(self, input_dim, num_filters, conv_kernel_size, pool_kernel_size, stride, padding, hidden_size, num_classes, device):\n","    super(net, self).__init__()\n","    self.input_dim = input_dim\n","    self.device = device\n","    self.num_filters = num_filters\n","    self.hidden_size = hidden_size\n","    conv_output_size = int((input_dim - conv_kernel_size + 2 * padding)/stride) + 1   # conv layer output size\n","    self.pool_output_size = int((conv_output_size - pool_kernel_size)/stride) + 1          # pooling layer output size\n","   \n","    self.conv = nn.Conv2d(1, num_filters, kernel_size = conv_kernel_size, stride = stride, padding = padding)     \n","    self.pool = nn.MaxPool2d(kernel_size = pool_kernel_size, stride = stride)\n","    self.rnn = nn.GRU(input_size = self.pool_output_size * self.pool_output_size, hidden_size = hidden_size)  # GRU layer that takes into CNN output\n","    self.relu = nn.ReLU()\n","    self.dense = nn.Linear(hidden_size, num_classes)     \n","    \n","  def forward(self, x):\n","    x = self.conv(x)\n","    x = self.relu(x)\n","    x = self.pool(x)\n","\n","    x = x.view(self.num_filters, x.size(0), self.pool_output_size * self.pool_output_size)   # resize to fit into GRU layer\n","    \n","    h0 = torch.from_numpy(np.zeros((1, x.size(1), self.hidden_size))).float().to(self.device)\n","    x, _ = self.rnn(x, h0)\n","    x = x[-1, :, :]                 # take only the last sequence output\n","    x = self.dense(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rP0Gt5E9ajmd","colab_type":"code","colab":{}},"source":["# hyperparameters\n","DEVICE = torch.device('cuda')\n","INPUT_DIM = 28\n","NUM_FILTERS = 64\n","HIDDEN_SIZE = 30\n","CONV_KERNEL_SIZE = 3\n","POOL_KERNEL_SIZE = 2\n","STRIDE = 1\n","PADDING = 1\n","HIDDEN_SIZE = 10\n","NUM_CLASSES = 10\n","LEARNING_RATE = 1e-1\n","NUM_EPOCHS = 10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPBm8qDrSWsi","colab_type":"code","colab":{}},"source":["model = net(INPUT_DIM, NUM_FILTERS, CONV_KERNEL_SIZE, POOL_KERNEL_SIZE, STRIDE, PADDING, HIDDEN_SIZE, NUM_CLASSES, DEVICE).to(DEVICE)\n","criterion = nn.CrossEntropyLoss()   # do not need softmax layer when using CEloss criterion\n","optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEBtAPYCFeic","colab_type":"code","outputId":"e366f356-582e-4707-dfad-65a11878af74","executionInfo":{"status":"ok","timestamp":1566589633642,"user_tz":240,"elapsed":67432,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# training for NUM_EPOCHS\n","for i in range(NUM_EPOCHS):\n","  temp_loss = []\n","  for (x, y) in train_loader:\n","    x, y = x.float().to(DEVICE), y.to(DEVICE)  # beware that input to embedding should be type 'long'\n","    outputs = model(x)\n","    loss = criterion(outputs, y)\n","    temp_loss.append(loss.item())\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","  print(\"Loss at {}th epoch: {}\".format(i, np.mean(temp_loss)))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Loss at 0th epoch: 2.3441601541759107\n","Loss at 1th epoch: 2.339597595780135\n","Loss at 2th epoch: 2.340265729025737\n","Loss at 3th epoch: 2.3395771812528436\n","Loss at 4th epoch: 2.337725659169114\n","Loss at 5th epoch: 2.3428904186687998\n","Loss at 6th epoch: 2.3376515308168653\n","Loss at 7th epoch: 2.3386383000721556\n","Loss at 8th epoch: 2.334579667557023\n","Loss at 9th epoch: 2.3355735863195553\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qpAJUiHm529m","colab_type":"text"},"source":["## 3. Evaluation\n","- Evaluate the trained CNN-RNN model with accuracy score \n","  - Store probability of each instance to a list and compare it with true y label"]},{"cell_type":"code","metadata":{"id":"txXH3dknFpSx","colab_type":"code","outputId":"386ee399-8ef7-4d21-c02a-881deb48a9eb","executionInfo":{"status":"ok","timestamp":1566589702589,"user_tz":240,"elapsed":1172,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["y_pred, y_true = [], []\n","with torch.no_grad():\n","  for x, y in test_loader:\n","    x, y = x.float().to(DEVICE), y.to(DEVICE)       # beware that input to embedding should be type 'long'\n","    outputs = F.softmax(model(x)).max(1)[-1]       # predicted label\n","    y_true += list(y.cpu().numpy())                # true label\n","    y_pred += list(outputs.cpu().numpy())   "],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  \"\"\"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HV1s3xf5Frkl","colab_type":"code","outputId":"fee63e50-58b3-4535-a973-a83071a9413d","executionInfo":{"status":"ok","timestamp":1566589703545,"user_tz":240,"elapsed":1086,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# evaluation result\n","from sklearn.metrics import accuracy_score\n","accuracy_score(y_true, y_pred)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.099"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"0bWX6LZvBdC8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}