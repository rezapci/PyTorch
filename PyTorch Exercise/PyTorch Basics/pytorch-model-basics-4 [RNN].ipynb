{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch-model-basics-4 [RNN].ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bIAYbYajk1w9","colab_type":"text"},"source":["<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","\n","      \n","| Name | Description | Date\n","| :- |-------------: | :-:\n","|Reza Hashemi| Training and evaluating machine learning models - 4th PyTorch Datasets  | On 23rd of August 2019 | width=\"750\" align=\"center\"></a></p>\n","</div>\n","\n","# Recurrent Neural Networks\n","- Vanilla RNN\n","- Gated Recurrent Units\n","- Long Short Term Memory"]},{"cell_type":"code","metadata":{"id":"GVU5-yp3N89I","colab_type":"code","outputId":"ef296b9a-bf6c-4347-fac0-18229a383696","executionInfo":{"status":"ok","timestamp":1566582502269,"user_tz":240,"elapsed":2583,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!pip3 install torch torchvision"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8yy37hEYOEiQ","colab_type":"code","outputId":"2922ac6a-a64a-4679-c028-c85f0b9c2523","executionInfo":{"status":"ok","timestamp":1566582507650,"user_tz":240,"elapsed":379,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import pandas as pd\n","import torch, torchvision\n","torch.__version__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.1.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"gyv2Sy5WO8lK","colab_type":"code","colab":{}},"source":["import torch.nn as nn"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XoCXfOh1RQun","colab_type":"text"},"source":["## 1. Vanilla RNN\n","![vanilla_RNN](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)\n","\n","\n","- Vanilla RNN can be implemented with ```torch.nn.RNN()``` \n","\n","- Key Parameters\n","  - ```input_size```:  number of expected features in the input (i.e., dimensionality of feature space)\n","  - ```hidden_size```: number of features in hidden state (i.e., dimensionality of output space)\n","  - ```num_layers```: number of recurrent layers (to create stacked RNN)\n","  - ```batch_first```: If ```True```, input and output tensor shapes are ```(batch_size, seq_length, dim_feature)```. If ```False```, ```(sequence_length, batch_size, dim_feature)```\n","  - ```bidirectional```: If ```True```, bidirectional RNN\n","  \n","- One thing to note is that unlike fully-connected layers or convolutional layers, RNNs take multi inputs/outputs\n","  - In addition to (sequential) inputs, RNN has another called hidden state, which makes RNN special\n","  - This hidden state sends information regarding current step to the next\\\n","  \n","- Inputs to RNN: ```(x0, h0)```\n","  - ```x0```: tensor that contains features of the input sequence\n","    - shape\n","      - ```(seq_len, batch_size, input_size)``` if ```batch_first == False``` (default)\n","      - ```(batch_size, seq_len, input_size)``` if ```batch_fist == True``` \n","  - ```h0```: tensor that contains hidden state for each instance\n","    - shape\n","      - ```(num_layers * num_directions, batch_size, hidden_size)```"]},{"cell_type":"code","metadata":{"id":"kp_YDg0aQQ0e","colab_type":"code","colab":{}},"source":["rnn = nn.RNN(input_size = 10, \n","             hidden_size = 5, \n","             num_layers = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtVnd-SJomFA","colab_type":"code","outputId":"9b1bab34-c6ed-464e-a61b-66a80ff46de5","executionInfo":{"status":"ok","timestamp":1566582510215,"user_tz":240,"elapsed":311,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## inputs to RNN\n","# input data (seq_len, batch_size, input_size)\n","x0 = torch.from_numpy(np.random.randn(12, 64, 10)).float()     \n","# hidden state (num_layers * num_directions, batch_size, hidden_size)\n","h0 = torch.from_numpy(np.zeros((1, 64, 5))).float()            \n","\n","print(x0.shape, h0.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([12, 64, 10]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fDyuMNs9oyQ-","colab_type":"code","outputId":"8c3e695a-7e10-45e1-dc2d-1e0f705a91dd","executionInfo":{"status":"ok","timestamp":1566582512304,"user_tz":240,"elapsed":1867,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## outputs from RNN\n","# output (seq_len, batch_size, num_directions * hidden_size)\n","# hidden state (num_layers * num_directions, batch_size, hidden_size)\n","out, h1 = rnn(x0, h0)\n","\n","print(out.shape, h1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([12, 64, 5]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LMcGMyJNSzSA","colab_type":"code","colab":{}},"source":["# when batch_first = True\n","rnn = nn.RNN(input_size = 10, \n","             hidden_size = 5, \n","             num_layers = 2,     # stacked RNN (2 layers)\n","             batch_first = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1wKPW7qiWZJt","colab_type":"code","outputId":"619b1b9a-0c57-4508-ffee-6d33fe29f3c9","executionInfo":{"status":"ok","timestamp":1566582512306,"user_tz":240,"elapsed":1349,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## inputs to RNN\n","x0 = torch.from_numpy(np.random.randn(64, 12, 10)).float()     \n","# note that even batch_first == True, hidden state shape order does not change\n","h0 = torch.from_numpy(np.zeros((2, 64, 5))).float()            \n","\n","print(x0.shape, h0.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([64, 12, 10]) torch.Size([2, 64, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aqUXKwvIXUH-","colab_type":"code","outputId":"2adda33d-0f94-4bb2-e175-41c3e4a5c9d6","executionInfo":{"status":"ok","timestamp":1566582514147,"user_tz":240,"elapsed":165,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## outputs from RNN\n","out, h1 = rnn(x0, h0)\n","\n","print(out.shape, h1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([64, 12, 5]) torch.Size([2, 64, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E4AJ3I9JWnyZ","colab_type":"code","outputId":"56a4f659-6203-4cd2-87df-5aedfee77e4e","executionInfo":{"status":"ok","timestamp":1566582514835,"user_tz":240,"elapsed":162,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# bidirectional, stacked RNN\n","rnn = nn.RNN(input_size = 20, \n","             hidden_size = 10, \n","             num_layers = 4,     \n","             bidirectional = True)\n","\n","x0 = torch.from_numpy(np.random.randn(5, 64, 20)).float()\n","h0 = torch.from_numpy(np.zeros((4 * 2, 64, 10))).float()  # notice the dimensionality of hidden state\n","out, h1 = rnn(x0, h0)\n","\n","print(out.shape, h1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([5, 64, 20]) torch.Size([8, 64, 10])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7jJnvcgAXpSq","colab_type":"text"},"source":["## 2. Gated Recurrent Units (GRU)\n","\n","![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Gated_Recurrent_Unit%2C_base_type.svg/780px-Gated_Recurrent_Unit%2C_base_type.svg.png)\n","\n","- GRU has rather complicated structure compared to vanilla RNN (see below figure), but in terms of implementing it with Pytorch, largely similar to RNN, using ```torch.nn.GRU```"]},{"cell_type":"code","metadata":{"id":"Irn1yF5lb3HO","colab_type":"code","colab":{}},"source":["gru = nn.GRU(input_size = 10, \n","             hidden_size = 5, \n","             num_layers = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddO_D_L2b81J","colab_type":"code","outputId":"4b049215-9f87-4268-fe8c-82cf5d82141d","executionInfo":{"status":"ok","timestamp":1566582517897,"user_tz":240,"elapsed":170,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## inputs to GRU\n","# input data (seq_len, batch_size, input_size)\n","x0 = torch.from_numpy(np.random.randn(12, 64, 10)).float()     \n","# hidden state (num_layers * num_directions, batch_size, hidden_size)\n","h0 = torch.from_numpy(np.zeros((1, 64, 5))).float()            \n","\n","print(x0.shape, h0.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([12, 64, 10]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ukQSVR0yY2VC","colab_type":"code","outputId":"1a554ec3-8db4-4d21-bc61-ceb9b13526f3","executionInfo":{"status":"ok","timestamp":1566582520331,"user_tz":240,"elapsed":156,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## outputs from GRU\n","# output (seq_len, batch_size, num_directions * hidden_size)\n","# hidden state (num_layers * num_directions, batch_size, hidden_size)\n","out, h1 = gru(x0, h0)\n","\n","print(out.shape, h1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([12, 64, 5]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MaM0ruFEtlQA","colab_type":"text"},"source":["## 3. Long Short Term Memory (LSTM)\n","\n","![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/1200px-The_LSTM_cell.png)\n","\n","- LSTM is another variant of vanilla RNN that is widely used. Though there exist some differences in structure, when implementing one just need to attend to the cell state (c_t)\n","  - Inputs to LSTM: (x0, (h0, c0)\n","    - ```x0```: tensor that contains features of the input sequence\n","      - shape: ```(seq_len, batch_size, input_size)```\n","    - ```h0```: tensor that contains initial hidden state\n","      - shape: ```(num_layers * num_directions, batch_size, hidden_size)```\n","    - ```c0```: tensor that contains initial cell state\n","      - shape: ```(num_layers * num_directions, batch_size, hidden_size)``` (same as h0)\n","  - Outputs to LSTM: (xn, (hn, cn))\n","    - ```xn```: tensor that contains output features from the last layer\n","      - shape: ```(seq_len, batch_size, num_directions * hidden_size)```\n","    - ```hn```: tensor containing the hidden state\n","      - shape: ```(num_layers * num_directions, batch_size, hidden_size)```\n","    - ```cn```: tensor containing the cell state\n","      - shape: ```(num_layers * num_directions, batch_size, hidden_size)```"]},{"cell_type":"code","metadata":{"id":"LSUeaLXatsK-","colab_type":"code","colab":{}},"source":["lstm = nn.LSTM(input_size = 10, \n","             hidden_size = 5, \n","             num_layers = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uOcAQRqSt826","colab_type":"code","outputId":"3e4d118e-af23-4b77-a6ef-3c2417051ca3","executionInfo":{"status":"ok","timestamp":1566582522718,"user_tz":240,"elapsed":179,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## inputs to LSTM\n","# input data (seq_len, batch_size, input_size)\n","x0 = torch.from_numpy(np.random.randn(1, 64, 10)).float()     \n","\n","print(x0.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1, 64, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iVEKLB3xLWAR","colab_type":"code","outputId":"cfdf23d0-b193-406d-cb91-001960f23cbf","executionInfo":{"status":"ok","timestamp":1566582523380,"user_tz":240,"elapsed":164,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# outputs from LSTM\n","# when initial hidden & cell state are not given, they are regarded as zero\n","xn, (hn, cn) = lstm(x0)\n","\n","print(xn.shape)               # (seq_len, batch_size, hidden_size)\n","print(hn.shape, cn.shape)     # (num_layers, batch_size, hidden_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1, 64, 5])\n","torch.Size([1, 64, 5]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uNiSC9sPLf_w","colab_type":"code","outputId":"0eba576a-fa49-4861-b16d-88d81daa751a","executionInfo":{"status":"ok","timestamp":1566582524158,"user_tz":240,"elapsed":157,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# when initial hidden & cell states are given\n","x0 = torch.from_numpy(np.random.randn(1, 64, 10)).float()     \n","h0, c0 = torch.from_numpy(np.zeros((1, 64, 5))).float(), torch.from_numpy(np.zeros((1, 64, 5))).float()\n","\n","xn, (hn, cn) = lstm(x0, (h0, c0))\n","\n","print(xn.shape)               # (seq_len, batch_size, hidden_size)\n","print(hn.shape, cn.shape)     # (num_layers, batch_size, hidden_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1, 64, 5])\n","torch.Size([1, 64, 5]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7uiNzfCkuhHu","colab_type":"code","colab":{}},"source":["# stacked, bidirectional LSTM\n","lstm = nn.LSTM(input_size = 10, \n","             hidden_size = 5, \n","             num_layers = 2,\n","             bidirectional = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3SLQllzOMhEN","colab_type":"code","outputId":"25d75628-8811-44e5-83fb-b80726e64157","executionInfo":{"status":"ok","timestamp":1566582525926,"user_tz":240,"elapsed":282,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# inputs to LSTM\n","x0 = torch.from_numpy(np.random.randn(5, 64, 10)).float()\n","h0, c0 = torch.from_numpy(np.zeros((4, 64, 5))).float(), torch.from_numpy(np.zeros((4, 64, 5))).float()\n","\n","xn, (hn, cn) = lstm(x0, (h0, c0))\n","\n","print(xn.shape)\n","print(hn.shape, cn.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([5, 64, 10])\n","torch.Size([4, 64, 5]) torch.Size([4, 64, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1VXtlmhTmE5b","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}