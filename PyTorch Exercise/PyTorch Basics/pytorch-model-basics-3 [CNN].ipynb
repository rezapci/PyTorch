{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch-model-basics-3 [CNN].ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bIAYbYajk1w9","colab_type":"text"},"source":["<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","\n","      \n","| Name | Description | Date\n","| :- |-------------: | :-:\n","|Reza Hashemi| Building Blocks of Models 3rd model  | On 23rd of August 2019 | width=\"750\" align=\"center\"></a></p>\n","</div>\n","\n","\n","# Building Blocks of Models\n","- Convolution & Pooling\n","- Padding"]},{"cell_type":"code","metadata":{"id":"GVU5-yp3N89I","colab_type":"code","outputId":"288b243e-2afd-4cf9-d954-b982ca2eddd7","executionInfo":{"status":"ok","timestamp":1566582115018,"user_tz":240,"elapsed":2083,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!pip3 install torch torchvision"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8yy37hEYOEiQ","colab_type":"code","outputId":"ab18695f-aacf-42b0-a936-a2b89c1347ed","executionInfo":{"status":"ok","timestamp":1566582026281,"user_tz":240,"elapsed":423,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import pandas as pd\n","import torch, torchvision\n","torch.__version__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.1.0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"gyv2Sy5WO8lK","colab_type":"code","colab":{}},"source":["import torch.nn as nn"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NAqYXyzcT-OJ","colab_type":"text"},"source":["## 1. Convolution & Pooling \n","Convolution and pooling are fundamental operations for building CNN models. There are a number of parameters and if their definitions are not clear, it could lead to great confusion.\n","- Parameters for convolution (pooling) layers\n","  - **stride:** how many \"steps\" that the filter makes for each advance\n","  - **kernel size**: how large is the kernel (filter) is\n","  - **number of filters (channels):** designates the \"depth\" of the data. Most image inputs have three filters (RGB)\n","  - **padding:** how to pad the input sample with zero in the border\n","- How to calculate output size of convolution/pooling operation\n","  <br> \n","*(W - F + 2P)/S + 1* <br>\n","  - *W*: input size\n","  - *F*: kernel size\n","  - *P*: padding \n","  - *S*: stride\n","  \n","![alt text](https://user-images.githubusercontent.com/22738317/34081046-c3a97518-e347-11e7-98fe-929f602ee857.png)"]},{"cell_type":"markdown","metadata":{"id":"XoCXfOh1RQun","colab_type":"text"},"source":["### 1. Convolution & Pooling 1D\n","\n","- ```torch.nn.Conv1d()```: 1D convolution\n","  - Input: (N, Fi, Li): basically, each input is ```Fi``` vectors of length ```Li```\n","    - N: batch size\n","    - Fi: number of input filters (or channels)\n","    - Li: length of input sequence\n","  - Output: (N, Fo, Lo): each output is ```Fo``` vectors of length ```Lo```\n","    - N: batch size\n","    - Fo: number of output filters (or channels)\n","    - Lo: length of output sequence"]},{"cell_type":"code","metadata":{"id":"kp_YDg0aQQ0e","colab_type":"code","outputId":"6bfe75bd-aa24-42f7-cb27-36307c1b66a9","executionInfo":{"status":"ok","timestamp":1566582030120,"user_tz":240,"elapsed":165,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# case 1 - kernel size = 1\n","conv1d = nn.Conv1d(16, 32, kernel_size = 1)\n","\n","x = torch.ones(128, 16, 10)   # input: batch_size = 128, num_filters = 16, seq_length = 10\n","print(conv1d(x).size())       # input and output size are equal when kernel_size = 1 (assuming no padding)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([128, 32, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LMcGMyJNSzSA","colab_type":"code","outputId":"ed3a0e45-ae69-4efd-bc8f-d4d7e14b57d7","executionInfo":{"status":"ok","timestamp":1566582030387,"user_tz":240,"elapsed":139,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# case 2 - kernel size = 2, stride = 1\n","conv1d = nn.Conv1d(16, 32, kernel_size = 2, padding = 2)\n","\n","x = torch.ones(128, 16, 10)   # input: batch_size = 128, num_filters = 16, seq_length = 10\n","print(conv1d(x).size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([128, 32, 13])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Irn1yF5lb3HO","colab_type":"code","outputId":"745ccef0-67a2-4c73-f733-30aead920f28","executionInfo":{"status":"ok","timestamp":1566582031120,"user_tz":240,"elapsed":166,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# case 2 - kernel size = 2, stride = 2\n","conv1d = nn.Conv1d(16, 64, kernel_size = 2, stride = 2, padding = 2)\n","\n","x = torch.ones(128, 16, 10)   # input: batch_size = 128, num_filters = 16, seq_length = 10\n","print(conv1d(x).size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([128, 64, 7])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6BF4TJ0Of1G1","colab_type":"text"},"source":["### Convolution & Pooling 2D\n","- ```torch.nn.Conv2d()```:  2D convolution\n","  - Largely siimilar to 1D-convolution, but input and outputs are 2-dimensional, rather than 1-dimensional\n","- Image data in Pytorch\n","  - ```Conv2d()``` is the basic building block of modern CNNs to process image, such as GoogleNet or ResNet\n","  - In Pytorch, images usually have shape of **\\[depth, height, width\\]**\n","    - depth corresponds to the number of filters (kernels)\n","    - width and height represent the size of an image. When the image is square (e.g., in CIFAR10), width = height\n","  \n","  ![alt text](http://cs231n.github.io/assets/cnn/cnn.jpeg)"]},{"cell_type":"code","metadata":{"id":"ddO_D_L2b81J","colab_type":"code","outputId":"55edceb8-8bd7-4192-8d2e-2669be03793e","executionInfo":{"status":"ok","timestamp":1566582032035,"user_tz":240,"elapsed":166,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# case 1 - kernel size = 1\n","conv2d = nn.Conv2d(16, 32, kernel_size = 1)  # if kernel size is integer, width and height are equal (i.e., square kernel) \n","\n","x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n","print(conv2d(x).size())       # input and output size are equal when kernel_size = 1 (assuming no padding)\n","\n","conv2d = nn.Conv2d(16, 32, kernel_size = (1, 1))  # same as kernel size = 1\n","\n","x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n","print(conv2d(x).size())       # input and output size are equal when kernel_size = 1 (assuming no padding)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([128, 32, 10, 10])\n","torch.Size([128, 32, 10, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kvg4w7Q7lJBT","colab_type":"code","outputId":"6c307156-31b8-4d70-9a24-7a71bbe02be9","executionInfo":{"status":"ok","timestamp":1566582033017,"user_tz":240,"elapsed":166,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# case 2 - kernel size = 2\n","conv2d = nn.Conv2d(16, 32, kernel_size = 2, padding = 1)  # if kernel size is integer, width and height are equal (i.e., square kernel) \n","\n","x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n","print(conv2d(x).size())       "],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([128, 32, 11, 11])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WMZooMlVljmy","colab_type":"code","outputId":"8453f12e-5936-4e0a-d82c-c626e87ded63","executionInfo":{"status":"ok","timestamp":1566582033755,"user_tz":240,"elapsed":171,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# case 3 - differing kernel size\n","conv2d = nn.Conv2d(16, 32, kernel_size = (2, 1))  # if kernel size is integer, width and height are equal (i.e., square kernel) \n","\n","x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n","print(conv2d(x).size())     # non-square output"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([128, 32, 9, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9A514b51lsxS","colab_type":"code","outputId":"db8a5df7-f2cc-4f14-cf08-727fecede047","executionInfo":{"status":"ok","timestamp":1566582034398,"user_tz":240,"elapsed":164,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# case 4 - kernel size = 3\n","conv2d = nn.Conv2d(16, 32, kernel_size = (3, 3), padding = 1)  # if kernel size is integer, width and height are equal (i.e., square kernel) \n","\n","x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n","print(conv2d(x).size())     # input and output size are equal"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([128, 32, 10, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"91PuKukfmK07","colab_type":"code","outputId":"9b6d47d4-76c1-41f0-b60b-01f69fad5e7f","executionInfo":{"status":"ok","timestamp":1566582034938,"user_tz":240,"elapsed":209,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# case 4 - kernel size = 3, stride = 2\n","conv2d = nn.Conv2d(16, 32, kernel_size = (3, 3), stride = 2)  # if kernel size is integer, width and height are equal (i.e., square kernel) \n","\n","x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n","print(conv2d(x).size())     # input and output size are equal"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([128, 32, 4, 4])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uxSuAXXRmjSJ","colab_type":"text"},"source":["## 2. Padding\n","- Zero padding can be applied in convolution/pooling as we have seen above. But custom padding can be applied as well\n","  - ```nn.ConstandPad1d(padding, value)```: apply constant padding on 1D data\n","    - ```padding```: the shape of padding (if tuple, (```padingLeft```, ```padingRight```))\n","    - ```value```: the value of padding\n","  - ```nn.ConstantPad2d(padding, value)```: apply constant padding on 2D data\n","    - ```padding```: the shape of padding (if tuple, (```padingLeft```, ```padingRight```, ```paddingTop```, ```padingBottom```))\n","    - ```value```: the value of padding\n","  - ```nn.ZeroPad2d(padding)```: apply zero padding on 2D data \n","    - ```padding```: the shape of padding (if tuple, (```padingLeft```, ```padingRight```, ```paddingTop```, ```padingBottom```))"]},{"cell_type":"code","metadata":{"id":"l8v3fQXooGyk","colab_type":"code","outputId":"138366c3-6272-4c64-bc36-2ee580d04734","executionInfo":{"status":"ok","timestamp":1566582036079,"user_tz":240,"elapsed":167,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["p = nn.ConstantPad1d(1, 0.75)  # 1d padding with constant 0.75\n","x = torch.ones(1, 1, 3)\n","print(p(x))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[[0.7500, 1.0000, 1.0000, 1.0000, 0.7500]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QCt72l7LpNoc","colab_type":"code","outputId":"6d29c7a7-58a7-462a-b6df-e5a6a679d797","executionInfo":{"status":"ok","timestamp":1566582036574,"user_tz":240,"elapsed":162,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["p = nn.ConstantPad2d((2, 2, 0, 0), -1)  # 2d padding with -1 (on right and left)\n","x = torch.ones(1, 1, 3, 3)\n","print(p(x))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[[[-1., -1.,  1.,  1.,  1., -1., -1.],\n","          [-1., -1.,  1.,  1.,  1., -1., -1.],\n","          [-1., -1.,  1.,  1.,  1., -1., -1.]]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k7ucMutomgGh","colab_type":"code","outputId":"63b6b95e-6a2d-4b8c-e599-8e311f87f0f9","executionInfo":{"status":"ok","timestamp":1566582037481,"user_tz":240,"elapsed":167,"user":{"displayName":"Reza Hashemi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrdPXZmzhldkZcu5l9nrnO7t-Ls96No7O8kRuZ=s64","userId":"14585138350013583795"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["p = nn.ZeroPad2d((1,0,0,0))  # apply zero padding only on the left of first column\n","x = torch.ones(1, 1, 3, 3)\n","print(p(x))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[[[0., 1., 1., 1.],\n","          [0., 1., 1., 1.],\n","          [0., 1., 1., 1.]]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KJYxb4wokNrr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}